{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#global parameters\n",
    "cudadir = \"/usr/common/software/cuda/10.0.130\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input and output dirs\n",
    "datadirs = [\"../data/tf_2.0b/test\"]\n",
    "outputdir = \"..\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transpose_frame(df_times, df_metrics):\n",
    "    #Copy the profile frame to make sure not to overwrite it and potentially read it in again if we screwed it up\n",
    "    selectkeys = [\"Precision\", \"Network Name\", \"Data Format\", \"Input Shape\", \"Kernel Shape\", \"Stride Size\", \"Batch Size\", \"Pass\", \"Name\"]\n",
    "    tc_peak_perf_flops = 125*10**12\n",
    "\n",
    "    #just pick the gpu activities for now\n",
    "    profiledf = df_times[ df_times[\"Collection Type\"] == \"gpu_activities\" ].copy()\n",
    "    profiledf.sort_values(by=[\"Name\"],inplace=True)\n",
    "    profiledf.reset_index(drop=True, inplace=True)\n",
    "    profiledf.rename(columns={\"Avg\": \"Time Avg\"}, inplace=True)\n",
    "    del profiledf[\"Time(%)\"]\n",
    "    del profiledf[\"Time\"]\n",
    "    del profiledf[\"Min\"]\n",
    "    del profiledf[\"Max\"]\n",
    "    del profiledf[\"Metric Name\"]\n",
    "    del profiledf[\"Collection Type\"]\n",
    "\n",
    "    #remove the calibration\n",
    "    alignkeys = selectkeys[:-2]\n",
    "    profiledf = profiledf.groupby(alignkeys).apply(lambda x: x[ (~x[\"Name\"].isin(x.loc[x[\"Pass\"].str.startswith(\"calibrate\"), \"Name\"].values)) ])\n",
    "    profiledf.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    #as metricdf use df_summary\n",
    "    metricdf = df_metrics.copy()\n",
    "\n",
    "    #now, get the AI-relevant stuff:\n",
    "    #FLOPS 32\n",
    "    flopdf = metricdf[ metricdf[\"Metric Name\"].str.contains(\"flop_count_sp\") ].sort_values(selectkeys).rename(columns={\"Avg\": \"FP32 Flops Avg\"})\n",
    "    #add to timings\n",
    "    profiledf = profiledf.merge(flopdf[selectkeys+[\"FP32 Flops Avg\"]], on=selectkeys, how=\"inner\")\n",
    "    \n",
    "    #monitor that: if that changes be warned\n",
    "    numrows = profiledf.shape[0]\n",
    "\n",
    "    #FLOPS 16 non-TC\n",
    "    flopdf = metricdf[ metricdf[\"Metric Name\"].str.contains(\"flop_count_hp\") ].sort_values(selectkeys).rename(columns={\"Avg\": \"FP16 non-TC Flops Avg\"})\n",
    "    #add to timings\n",
    "    mergedf = profiledf.merge(flopdf[selectkeys+[\"FP16 non-TC Flops Avg\"]], on=selectkeys, how=\"inner\")\n",
    "\n",
    "    #check\n",
    "    if mergedf.shape[0] != numrows:\n",
    "        #print(profiledf, flopdf)\n",
    "        raise ValueError(\"Something went wrong, check consistency of inputs\")\n",
    "    else:\n",
    "        profiledf = mergedf\n",
    "    \n",
    "    \n",
    "    #FLOPS TC\n",
    "    flopdf = metricdf[ metricdf[\"Metric Name\"].str.contains(\"tensor_precision_fu_utilization\") ].sort_values(selectkeys).rename(columns={\"Avg\": \"TC Flops Avg\"})\n",
    "    tmpdf = flopdf.merge(profiledf, how=\"inner\", on=selectkeys).sort_values(selectkeys)\n",
    "    tmpdf[\"TC Flops Avg\"] *= tc_peak_perf_flops/10. * tmpdf[\"Time Avg\"]\n",
    "    #add to timings\n",
    "    mergedf = profiledf.merge(tmpdf[selectkeys+[\"TC Flops Avg\"]], on=selectkeys, how=\"inner\")\n",
    "\n",
    "    #check\n",
    "    if mergedf.shape[0] != numrows:\n",
    "        raise ValueError(\"Something went wrong, check consistency of inputs\")\n",
    "    else:\n",
    "        profiledf = mergedf\n",
    "\n",
    "    \n",
    "    #fill NA values here\n",
    "    profiledf.fillna(0., inplace=True)\n",
    "\n",
    "    #FLOPS FP16: add TC and non-TC FP16 flops together\n",
    "    profiledf[\"FP16 Flops Avg\"] = profiledf[\"TC Flops Avg\"] + profiledf[\"FP16 non-TC Flops Avg\"]\n",
    "\n",
    "    #total flops\n",
    "    profiledf[\"Flops Avg\"] = profiledf[\"FP16 Flops Avg\"] + profiledf[\"FP32 Flops Avg\"]\n",
    "\n",
    "    #flop fractions\n",
    "    profiledf[\"TC Flops Fraction Avg\"] = profiledf[\"TC Flops Avg\"]/profiledf[\"Flops Avg\"]\n",
    "    profiledf[\"FP16 Flops Fraction Avg\"] = profiledf[\"FP16 Flops Avg\"]/profiledf[\"Flops Avg\"]\n",
    "    profiledf[\"FP16 non-TC Flops Fraction Avg\"] = profiledf[\"FP16 non-TC Flops Avg\"]/profiledf[\"Flops Avg\"]\n",
    "    profiledf[\"FP32 Flops Fraction Avg\"] = profiledf[\"FP32 Flops Avg\"]/profiledf[\"Flops Avg\"]\n",
    "\n",
    "\n",
    "    #shared\n",
    "    #project out\n",
    "    shareddf = metricdf[ metricdf[\"Metric Name\"].str.contains(\"shared\") ].sort_values(selectkeys)\n",
    "    #get reads and writes\n",
    "    sharedreadsdf = shareddf.loc[(shareddf[\"Metric Name\"]==\"shared_transactions\") & (shareddf[\"Metric Mode\"]==\"read\"), selectkeys+[\"Avg\"]]\n",
    "    sharedwritesdf = shareddf.loc[(shareddf[\"Metric Name\"]==\"shared_transactions\") & (shareddf[\"Metric Mode\"]==\"write\"), selectkeys+[\"Avg\"]]\n",
    "    #combine\n",
    "    shareddf = sharedwritesdf.merge(sharedreadsdf, on=selectkeys, how=\"outer\").fillna(0.)\n",
    "    shareddf[\"Shared Transactions Avg\"] = shareddf[\"Avg_x\"] + shareddf[\"Avg_y\"]\n",
    "    #add to timings\n",
    "    mergedf = profiledf.merge(shareddf[selectkeys+[\"Shared Transactions Avg\"]], on=selectkeys, how=\"inner\")\n",
    "\n",
    "    #check\n",
    "    if mergedf.shape[0] != numrows:\n",
    "        #get the complement:\n",
    "        print(profiledf[ ~profiledf.index.isin(mergedf.index) ])\n",
    "        raise ValueError(\"Something went wrong, check consistency of inputs\")\n",
    "    else:\n",
    "        profiledf = mergedf\n",
    "    \n",
    "    \n",
    "    #atomic\n",
    "    #project out\n",
    "    atomicdf = metricdf[ metricdf[\"Metric Name\"] == \"atomic_transactions\" ].sort_values(selectkeys)\n",
    "    #get reads and writes\n",
    "    atomicdf = atomicdf[selectkeys+[\"Avg\"]].rename(columns={\"Avg\": \"Atomic Transactions Avg\"})\n",
    "    #add to timings\n",
    "    mergedf = profiledf.merge(atomicdf[selectkeys+[\"Atomic Transactions Avg\"]], on=selectkeys, how=\"inner\")\n",
    "    \n",
    "    #check\n",
    "    if mergedf.shape[0] != numrows:\n",
    "        #get the complement:\n",
    "        print(profiledf[ ~profiledf.index.isin(mergedf.index) ])\n",
    "        raise ValueError(\"Something went wrong, check consistency of inputs\")\n",
    "    else:\n",
    "        profiledf = mergedf\n",
    "\n",
    "    \n",
    "    #L1\n",
    "    #project out\n",
    "    l1df = metricdf[ (metricdf[\"Metric Name\"].str.contains(\"gst_\")) | (metricdf[\"Metric Name\"].str.contains(\"gld_\")) ].sort_values(selectkeys)\n",
    "    #get reads and writes\n",
    "    l1readsdf = l1df.loc[(l1df[\"Metric Name\"]==\"gld_transactions\"), selectkeys+[\"Avg\"]]\n",
    "    l1writesdf = l1df.loc[(l1df[\"Metric Name\"]==\"gst_transactions\"), selectkeys+[\"Avg\"]]\n",
    "    #combine\n",
    "    l1df = l1writesdf.merge(l1readsdf, on=selectkeys, how=\"outer\").fillna(0.)\n",
    "    l1df[\"L1 Transactions Avg\"] = l1df[\"Avg_x\"] + l1df[\"Avg_y\"]\n",
    "    #add to timings\n",
    "    mergedf = profiledf.merge(l1df[selectkeys+[\"L1 Transactions Avg\"]], on=selectkeys, how=\"inner\")\n",
    "\n",
    "    #check\n",
    "    if mergedf.shape[0] != numrows:\n",
    "        print(profiledf, l1df)\n",
    "        raise ValueError(\"Something went wrong, check consistency of inputs\")\n",
    "    else:\n",
    "        profiledf = mergedf\n",
    "\n",
    "    \n",
    "    #L2\n",
    "    #project out\n",
    "    l2df = metricdf[ metricdf[\"Metric Name\"].str.contains(\"l2\") ].sort_values(selectkeys)\n",
    "    #get reads and writes\n",
    "    l2readsdf = l2df.loc[(l2df[\"Metric Name\"]==\"l2_transactions\") & (l2df[\"Metric Mode\"]==\"read\"), selectkeys+[\"Avg\"]]\n",
    "    l2writesdf = l2df.loc[(l2df[\"Metric Name\"]==\"l2_transactions\") & (l2df[\"Metric Mode\"]==\"write\"), selectkeys+[\"Avg\"]]\n",
    "    #combine\n",
    "    l2df = l2writesdf.merge(l2readsdf, on=selectkeys, how=\"outer\").fillna(0.)\n",
    "    l2df[\"L2 Transactions Avg\"] = l2df[\"Avg_x\"] + l2df[\"Avg_y\"]\n",
    "    #add to timings\n",
    "    mergedf = profiledf.merge(l2df[selectkeys+[\"L2 Transactions Avg\"]], on=selectkeys, how=\"inner\")\n",
    "\n",
    "    #check\n",
    "    if mergedf.shape[0] != numrows:\n",
    "        print(profiledf, l2df)\n",
    "        raise ValueError(\"Something went wrong, check consistency of inputs\")\n",
    "    else:\n",
    "        profiledf = mergedf\n",
    "    \n",
    "    \n",
    "    #DRAM\n",
    "    #project out\n",
    "    dramdf = metricdf[ metricdf[\"Metric Name\"].str.contains(\"dram\") ].sort_values(selectkeys)\n",
    "    #get reads and writes\n",
    "    dramreadsdf = dramdf.loc[(dramdf[\"Metric Name\"]==\"dram_transactions\") & (dramdf[\"Metric Mode\"]==\"read\"), selectkeys+[\"Avg\"]]\n",
    "    dramwritesdf = dramdf.loc[(dramdf[\"Metric Name\"]==\"dram_transactions\") & (dramdf[\"Metric Mode\"]==\"write\"), selectkeys+[\"Avg\"]]\n",
    "    #combine\n",
    "    dramdf = dramwritesdf.merge(dramreadsdf, on=selectkeys, how=\"outer\").fillna(0.)\n",
    "    dramdf[\"DRAM Transactions Avg\"] = dramdf[\"Avg_x\"] + dramdf[\"Avg_y\"]\n",
    "    tempdf = dramdf[dramdf['Pass'] != 'calibrate']\n",
    "    #print(tempdf[['Name', 'Avg_x', 'Avg_y']])\n",
    "    #add to timings\n",
    "    mergedf = profiledf.merge(dramdf[selectkeys+[\"DRAM Transactions Avg\"]], on=selectkeys, how=\"inner\")\n",
    "\n",
    "    #check\n",
    "    if mergedf.shape[0] != numrows:\n",
    "        print(profiledf, dramdf)\n",
    "        raise ValueError(\"Something went wrong, check consistency of inputs\")\n",
    "    else:\n",
    "        profiledf = mergedf\n",
    "    \n",
    "\n",
    "    #SYSMEM\n",
    "    #project out\n",
    "    sysmemdf = metricdf[ metricdf[\"Metric Name\"].str.contains(\"sysmem\") ].sort_values(selectkeys)\n",
    "    #get reads and writes\n",
    "    sysmemreadsdf = sysmemdf.loc[(sysmemdf[\"Metric Name\"]==\"sysmem_transactions\") & (sysmemdf[\"Metric Mode\"]==\"read\"), selectkeys+[\"Avg\"]]\n",
    "    sysmemwritesdf = sysmemdf.loc[(sysmemdf[\"Metric Name\"]==\"sysmem_transactions\") & (sysmemdf[\"Metric Mode\"]==\"write\"), selectkeys+[\"Avg\"]]\n",
    "    #combine\n",
    "    sysmemdf = sysmemwritesdf.merge(sysmemreadsdf, on=selectkeys, how=\"outer\").fillna(0.)\n",
    "    sysmemdf[\"Sysmem Transactions Avg\"] = sysmemdf[\"Avg_x\"] + sysmemdf[\"Avg_y\"]\n",
    "    #add to timings\n",
    "    mergedf = profiledf.merge(sysmemdf[selectkeys+[\"Sysmem Transactions Avg\"]], on=selectkeys, how=\"inner\")\n",
    "\n",
    "    #check\n",
    "    if mergedf.shape[0] != numrows:\n",
    "        print(profiledf, sysmemdf)\n",
    "        raise ValueError(\"Something went wrong, check consistency of inputs\")\n",
    "    else:\n",
    "        profiledf = mergedf\n",
    "    \n",
    "\n",
    "    #clean up and sort:\n",
    "    profiledf.sort_values(selectkeys).reset_index(drop=True, inplace=True)\n",
    "\n",
    "    #get performance first\n",
    "    profiledf[\"Performance GFlop/s\"] = profiledf[\"Flops Avg\"]/(profiledf[\"Time Avg\"]*10**9)\n",
    "    profiledf[\"FP32 Performance GFlop/s\"] = profiledf[\"FP32 Flops Avg\"]/(profiledf[\"Time Avg\"]*10**9)\n",
    "    profiledf[\"FP16 Performance GFlop/s\"] = profiledf[\"FP16 Flops Avg\"]/(profiledf[\"Time Avg\"]*10**9)\n",
    "    profiledf[\"TC Performance GFlop/s\"] = profiledf[\"TC Flops Avg\"]/(profiledf[\"Time Avg\"]*10**9)\n",
    "\n",
    "    #get AI:\n",
    "    #L1 is L1+shared\n",
    "    profiledf[\"L1 AI\"] = profiledf[\"Flops Avg\"]/(32.*(profiledf[\"L1 Transactions Avg\"]+profiledf[\"Shared Transactions Avg\"]+profiledf[\"Atomic Transactions Avg\"]))\n",
    "    profiledf[\"FP32 L1 AI\"] = profiledf[\"FP32 Flops Avg\"]/(32.*(profiledf[\"L1 Transactions Avg\"]+profiledf[\"Shared Transactions Avg\"]+profiledf[\"Atomic Transactions Avg\"]))\n",
    "    profiledf[\"FP16 L1 AI\"] = profiledf[\"FP16 Flops Avg\"]/(32.*(profiledf[\"L1 Transactions Avg\"]+profiledf[\"Shared Transactions Avg\"]+profiledf[\"Atomic Transactions Avg\"]))\n",
    "    #L2\n",
    "    profiledf[\"L2 AI\"] = profiledf[\"Flops Avg\"]/(32.*profiledf[\"L2 Transactions Avg\"])\n",
    "    profiledf[\"FP32 L2 AI\"] = profiledf[\"FP32 Flops Avg\"]/(32.*profiledf[\"L2 Transactions Avg\"])\n",
    "    profiledf[\"FP16 L2 AI\"] = profiledf[\"FP16 Flops Avg\"]/(32.*profiledf[\"L2 Transactions Avg\"])\n",
    "    #DRAM\n",
    "    profiledf[\"DRAM AI\"] = profiledf[\"Flops Avg\"]/(32.*profiledf[\"DRAM Transactions Avg\"])\n",
    "    profiledf[\"FP32 DRAM AI\"] = profiledf[\"FP32 Flops Avg\"]/(32.*profiledf[\"DRAM Transactions Avg\"])\n",
    "    profiledf[\"FP16 DRAM AI\"] = profiledf[\"FP16 Flops Avg\"]/(32.*profiledf[\"DRAM Transactions Avg\"])\n",
    "    #Sysmem\n",
    "    profiledf[\"Sysmem AI\"] = profiledf[\"Flops Avg\"]/(32.*profiledf[\"Sysmem Transactions Avg\"])\n",
    "    profiledf[\"FP32 Sysmem AI\"] = profiledf[\"FP32 Flops Avg\"]/(32.*profiledf[\"Sysmem Transactions Avg\"])\n",
    "    profiledf[\"FP16 Sysmem AI\"] = profiledf[\"FP16 Flops Avg\"]/(32.*profiledf[\"Sysmem Transactions Avg\"])\n",
    "\n",
    "    #sort results\n",
    "    profiledf.sort_values(by=selectkeys).reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    return profiledf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check for Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prefix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get metric list\n",
    "files = []\n",
    "for datadir in datadirs:\n",
    "    files += [ os.path.join(datadir,x) for x in os.listdir(datadir) if (os.path.splitext(x)[-1] == \".nvprof\") or (os.path.splitext(x)[-1] == \".nvvp\") ]\n",
    "\n",
    "#recs\n",
    "records = []\n",
    "\n",
    "#build feature list:\n",
    "for path in files:\n",
    "    \n",
    "    #filename\n",
    "    file = os.path.basename(path)\n",
    "    \n",
    "    #path\n",
    "    path = os.path.dirname(path)\n",
    "    \n",
    "    #splitup\n",
    "    splt = file.split(\".\")\n",
    "    \n",
    "    prefix = \".\".join(splt[0:-2])\n",
    "    metric = splt[-2].split(\"metric_\")[1]\n",
    "    \n",
    "    #append to records\n",
    "    records.append({\"prefix\": prefix, \"metric\": metric, \"file\": os.path.join(path, file)})\n",
    "\n",
    "#put in df\n",
    "recorddf = pd.DataFrame(records).sort_values([\"prefix\", \"metric\"])\n",
    "\n",
    "#get all metrics\n",
    "all_metrics = list(recorddf[\"metric\"].unique())\n",
    "\n",
    "#group by metric:\n",
    "missingrecorddf = pd.DataFrame(recorddf.groupby(\"prefix\").apply(lambda x: pd.Series([y for y in all_metrics if y not in list(x[\"metric\"])])))\n",
    "\n",
    "#create exclusion list:\n",
    "excludelist = list(missingrecorddf.reset_index()[\"prefix\"].unique())\n",
    "\n",
    "#print the missing ones\n",
    "missingrecorddf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check for Duplicate Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##datadir:\n",
    "#datadirs = [\"./data/good_new\", \"./data/good_new_2\"]\n",
    "#\n",
    "##do the brute force comparison\n",
    "#for id1, datadir_1 in enumerate(datadirs):\n",
    "#    \n",
    "#    #files 1\n",
    "#    files_1 = [ x for x in os.listdir(datadir_1) if (os.path.splitext(x)[-1] == \".nvprof\") or (os.path.splitext(x)[-1] == \".nvvp\") ]\n",
    "#    \n",
    "#    for id2 in range(id1+1,len(datadirs)):\n",
    "#        \n",
    "#        datadir_2 = datadirs[id2]\n",
    "#        \n",
    "#        #files 2\n",
    "#        files_2 = [ x for x in os.listdir(datadir_2) if (os.path.splitext(x)[-1] == \".nvprof\") or (os.path.splitext(x)[-1] == \".nvvp\") ]\n",
    "#        \n",
    "#        #report dups:\n",
    "#        dups = [x for x in files_1 if x in files_2]\n",
    "#        \n",
    "#        #print\n",
    "#        print(\"Duplicates in {} and {}:\".format(datadir_1, datadir_2))\n",
    "#        \n",
    "#        #move dups out of the way\n",
    "#        if not os.path.isdir(os.path.join(datadir_2,\"redundant\")):\n",
    "#            os.mkdir(os.path.join(datadir_2,\"redundant\"))\n",
    "#        for file in dups:\n",
    "#            source = os.path.join(datadir_2,file)\n",
    "#            target = os.path.join(datadir_2,\"redundant\",file)\n",
    "#            print(\"Move {} to {}\".format(source,target))\n",
    "#            shutil.move(source,target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort by those keys:\n",
    "sortkeys = [\"Network Name\", \"Input Shape\", \"Kernel Shape\", \\\n",
    "            \"Batch Size\", \"Stride Size\", \"Data Format\", \"Pass\", \\\n",
    "            \"Precision\", \"Device\", \"Name\", \"Metric Name\"]\n",
    "\n",
    "#limit the input\n",
    "#recorddf = recorddf[ recorddf[\"prefix\"].str.startswith(\"profile.name_ResNet50-2.batchsize_16.inputshape_112x112x64.kernelshape_7x7x64x64.stride_2.dataformat_NHWC.fp32\") ]\n",
    "\n",
    "#group by prefixes and files\n",
    "all_prefixes = set([x.split(\".pass\")[0] for x in recorddf[\"prefix\"]])\n",
    "all_metrics = recorddf[\"metric\"].unique()\n",
    "all_passes = set([x.split(\".pass_\")[1].replace(\".pass_\",\"\") for x in recorddf[\"prefix\"].unique()])\n",
    "\n",
    "#metrics\n",
    "df_profiles = []\n",
    "\n",
    "for pref in all_prefixes:\n",
    "    \n",
    "    #set empty lists\n",
    "    df_times = []\n",
    "    df_timeline = []\n",
    "    df_summary = []\n",
    "    \n",
    "    #print prefix\n",
    "    #print(pref)\n",
    "    \n",
    "    #loop over passes\n",
    "    for pas in all_passes:\n",
    "        \n",
    "        #project frame\n",
    "        selectdf = recorddf[ recorddf[\"prefix\"] == pref + \".pass_\" + pas ]\n",
    "        \n",
    "        #loop over metrics\n",
    "        for met in [x for x in all_metrics if x != \"time\"]:\n",
    "            \n",
    "            #filename\n",
    "            file = selectdf.loc[ selectdf[\"metric\"] == met, \"file\" ].values[0]\n",
    "        \n",
    "            #extract metric name\n",
    "            parameters, metric = parse_filename_nvprof(os.path.basename(file))\n",
    "            metrics = metric.split(\"-\")\n",
    "    \n",
    "            #import as timeline\n",
    "            tmpdf = import_nvprof_metric(file, timeline=True, cuda_dir=cudadir)\n",
    "            for key in parameters:\n",
    "                tmpdf[key] = parameters[key]\n",
    "        \n",
    "            #replace \"Idle (0)\" with 0.:\n",
    "            for metric in metrics:\n",
    "                if metric==\"tensor_precision_fu_utilization\":\n",
    "                    tmpdf[metric] = tmpdf[metric].apply(lambda x: replace_tc_string(x))\n",
    "    \n",
    "            #combine read and write metrics\n",
    "            tmpdf = tmpdf.groupby([x for x in tmpdf.columns if x not in metrics]).apply(lambda x: combine_metrics(x, metrics)).reset_index()\n",
    "            lev = [x for x in tmpdf.columns if x.startswith(\"level_\")][0]\n",
    "            del tmpdf[lev]\n",
    "            df_timeline.append(tmpdf)\n",
    "    \n",
    "            #import as summary\n",
    "            tmpdf = import_nvprof_metric(file, timeline=False, cuda_dir=cudadir).sort_values(by=\"Name\").reset_index(drop=True)\n",
    "            tmpdf[\"Metric Mode\"] = \"read\" if \"read\" in metric else \"write\" if \"write\" in metric else \"write\" if \"store\" in metric else \"read\" if \"load\" in metric else \"total\"\n",
    "            tmpdf[\"Metric Name\"] = metric.replace(\"read\",\"\").replace(\"write\",\"\").replace(\"store\",\"\").replace(\"load\",\"\").replace(\"__\",\"_\")\n",
    "            for key in parameters:\n",
    "                tmpdf[key] = parameters[key]\n",
    "            del tmpdf[\"Metric Description\"]\n",
    "    \n",
    "            #replace \"Idle (0)\" with 0.:\n",
    "            for metric in metrics:\n",
    "                if metric==\"tensor_precision_fu_utilization\":\n",
    "                    tmpdf[ \"Min\" ] = tmpdf[ \"Min\" ].apply(lambda x: replace_tc_string(x))\n",
    "                    tmpdf[ \"Max\" ] = tmpdf[ \"Max\" ].apply(lambda x: replace_tc_string(x))\n",
    "                    tmpdf[ \"Avg\" ] = tmpdf[ \"Avg\" ].apply(lambda x: replace_tc_string(x))\n",
    "            df_summary.append(tmpdf)\n",
    "        \n",
    "        #do time now\n",
    "        file = selectdf.loc[ selectdf[\"metric\"] == \"time\", \"file\" ].values[0]\n",
    "        timedf, markerdf = import_nvprof_overview(file, cuda_dir=cudadir)\n",
    "    \n",
    "        #extract metric name\n",
    "        parameters, _ = parse_filename_nvprof(os.path.basename(file))\n",
    "        for key in parameters:\n",
    "            timedf[key] = parameters[key]\n",
    "        df_times.append(timedf)\n",
    "        \n",
    "    #concat into frame\n",
    "    metricdf = pd.concat(df_summary, sort=True)\n",
    "    timedf = pd.concat(df_times, sort=True)\n",
    "    \n",
    "    #transpose\n",
    "    profiledf = transpose_frame(timedf, metricdf)\n",
    "    df_profiles.append(profiledf)\n",
    "\n",
    "#concat everything\n",
    "profiledf = pd.concat(df_profiles)\n",
    "profiledf.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute AI Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#profiledf[ (profiledf[\"Network Name\"]==\"ResNet50-2\") &\\\n",
    "#           (profiledf[\"Input Shape\"]==\"112x112x64\") &\\\n",
    "#           (profiledf[\"Batch Size\"]==16) &\\\n",
    "#           (profiledf[\"Precision\"]==\"FP32\") &\\\n",
    "#           (profiledf[\"Stride Size\"]==2) &\\\n",
    "#           (profiledf[\"Pass\"]==\"forward\") &\\\n",
    "#           (profiledf[\"Kernel Shape\"]==\"7x7x64x64\")\n",
    "#         ]\n",
    "#tmplist = ['Name', 'Calls', 'Pass', 'L1 Transactions Avg', 'L2 Transactions Avg', 'DRAM Transactions Avg']\n",
    "#display(profiledf[tmplist])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sum over all kernels\n",
    "combinedselectkeys = [\"Precision\", \"Network Name\", \"Data Format\", \"Input Shape\", \"Kernel Shape\", \"Stride Size\", \\\n",
    "                     \"Batch Size\", \"Pass\"]\n",
    "\n",
    "#copy profiledf\n",
    "combineddf = profiledf.copy()\n",
    "\n",
    "#get the aggregated performance, including all kernels:\n",
    "#compute weights: multiply all measures by the number of invocations\n",
    "weighted = True\n",
    "if weighted:\n",
    "    #first, get all the names of metrics which need to be weighted\n",
    "    metrics = [x for x in combineddf.columns if \"Avg\" in x]\n",
    "    for metric in metrics:\n",
    "        combineddf[metric] *= combineddf[\"Calls\"]\n",
    "    \n",
    "#sum up\n",
    "combineddf = combineddf.groupby(by=combinedselectkeys).sum().reset_index()\n",
    "\n",
    "#the flop fractions need to be recomputed\n",
    "combineddf[\"TC Flops Fraction Avg\"] = combineddf[\"TC Flops Avg\"]/combineddf[\"Flops Avg\"]\n",
    "combineddf[\"FP16 Flops Fraction Avg\"] = combineddf[\"FP16 Flops Avg\"]/combineddf[\"Flops Avg\"]\n",
    "combineddf[\"FP16 non-TC Flops Fraction Avg\"] = combineddf[\"FP16 non-TC Flops Avg\"]/combineddf[\"Flops Avg\"]\n",
    "combineddf[\"FP32 Flops Fraction Avg\"] = combineddf[\"FP32 Flops Avg\"]/combineddf[\"Flops Avg\"]\n",
    "\n",
    "#get performance first\n",
    "combineddf[\"Performance GFlop/s\"] = combineddf[\"Flops Avg\"]/(combineddf[\"Time Avg\"]*10**9)\n",
    "combineddf[\"FP32 Performance GFlop/s\"] = combineddf[\"FP32 Flops Avg\"]/(combineddf[\"Time Avg\"]*10**9)\n",
    "combineddf[\"FP16 Performance GFlop/s\"] = combineddf[\"FP16 Flops Avg\"]/(combineddf[\"Time Avg\"]*10**9)\n",
    "combineddf[\"TC Performance GFlop/s\"] = combineddf[\"TC Flops Avg\"]/(combineddf[\"Time Avg\"]*10**9)\n",
    "\n",
    "#get AI:\n",
    "#L1 is L1+shared\n",
    "combineddf[\"L1 AI\"] = combineddf[\"Flops Avg\"]/(32.*(combineddf[\"L1 Transactions Avg\"]+combineddf[\"Shared Transactions Avg\"]+combineddf[\"Atomic Transactions Avg\"]))\n",
    "combineddf[\"FP32 L1 AI\"] = combineddf[\"FP32 Flops Avg\"]/(32.*(combineddf[\"L1 Transactions Avg\"]+combineddf[\"Shared Transactions Avg\"]+combineddf[\"Atomic Transactions Avg\"]))\n",
    "combineddf[\"FP16 L1 AI\"] = combineddf[\"FP16 Flops Avg\"]/(32.*(combineddf[\"L1 Transactions Avg\"]+combineddf[\"Shared Transactions Avg\"]+combineddf[\"Atomic Transactions Avg\"]))\n",
    "combineddf[\"TC L1 AI\"] = combineddf[\"TC Flops Avg\"]/(32.*(combineddf[\"L1 Transactions Avg\"]+combineddf[\"Shared Transactions Avg\"]+combineddf[\"Atomic Transactions Avg\"]))\n",
    "#L2\n",
    "combineddf[\"L2 AI\"] = combineddf[\"Flops Avg\"]/(32.*combineddf[\"L2 Transactions Avg\"])\n",
    "combineddf[\"FP32 L2 AI\"] = combineddf[\"FP32 Flops Avg\"]/(32.*combineddf[\"L2 Transactions Avg\"])\n",
    "combineddf[\"FP16 L2 AI\"] = combineddf[\"FP16 Flops Avg\"]/(32.*combineddf[\"L2 Transactions Avg\"])\n",
    "combineddf[\"TC L2 AI\"] = combineddf[\"TC Flops Avg\"]/(32.*combineddf[\"L2 Transactions Avg\"])\n",
    "#DRAM\n",
    "combineddf[\"DRAM AI\"] = combineddf[\"Flops Avg\"]/(32.*combineddf[\"DRAM Transactions Avg\"])\n",
    "combineddf[\"FP32 DRAM AI\"] = combineddf[\"FP32 Flops Avg\"]/(32.*combineddf[\"DRAM Transactions Avg\"])\n",
    "combineddf[\"FP16 DRAM AI\"] = combineddf[\"FP16 Flops Avg\"]/(32.*combineddf[\"DRAM Transactions Avg\"])\n",
    "combineddf[\"TC DRAM AI\"] = combineddf[\"TC Flops Avg\"]/(32.*combineddf[\"DRAM Transactions Avg\"])\n",
    "#Sysmem\n",
    "combineddf[\"Sysmem AI\"] = combineddf[\"Flops Avg\"]/(32.*combineddf[\"Sysmem Transactions Avg\"])\n",
    "combineddf[\"FP32 Sysmem AI\"] = combineddf[\"FP32 Flops Avg\"]/(32.*combineddf[\"Sysmem Transactions Avg\"])\n",
    "combineddf[\"FP16 Sysmem AI\"] = combineddf[\"FP16 Flops Avg\"]/(32.*combineddf[\"Sysmem Transactions Avg\"])\n",
    "combineddf[\"TC Sysmem AI\"] = combineddf[\"TC Flops Avg\"]/(32.*combineddf[\"Sysmem Transactions Avg\"])\n",
    "\n",
    "#print\n",
    "#combineddf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time Avg</th>\n",
       "      <th>FP32 Flops Avg</th>\n",
       "      <th>FP16 non-TC Flops Avg</th>\n",
       "      <th>FP16 Flops Avg</th>\n",
       "      <th>Flops Avg</th>\n",
       "      <th>L1 Transactions Avg</th>\n",
       "      <th>L2 Transactions Avg</th>\n",
       "      <th>DRAM Transactions Avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.042112</td>\n",
       "      <td>2472714240</td>\n",
       "      <td>542023680</td>\n",
       "      <td>1.251488e+12</td>\n",
       "      <td>1.253960e+12</td>\n",
       "      <td>933788820</td>\n",
       "      <td>905672900</td>\n",
       "      <td>397753220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.006987</td>\n",
       "      <td>256901120</td>\n",
       "      <td>16056320</td>\n",
       "      <td>2.034791e+11</td>\n",
       "      <td>2.037360e+11</td>\n",
       "      <td>114351480</td>\n",
       "      <td>112022420</td>\n",
       "      <td>66151120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time Avg  FP32 Flops Avg  FP16 non-TC Flops Avg  FP16 Flops Avg  \\\n",
       "0  0.042112      2472714240              542023680    1.251488e+12   \n",
       "1  0.006987       256901120               16056320    2.034791e+11   \n",
       "\n",
       "      Flops Avg  L1 Transactions Avg  L2 Transactions Avg  \\\n",
       "0  1.253960e+12            933788820            905672900   \n",
       "1  2.037360e+11            114351480            112022420   \n",
       "\n",
       "   DRAM Transactions Avg  \n",
       "0              397753220  \n",
       "1               66151120  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#display(combineddf.columns)\n",
    "display(combineddf[['Time Avg', 'FP32 Flops Avg', 'FP16 non-TC Flops Avg', 'FP16 Flops Avg', 'Flops Avg', 'L1 Transactions Avg', 'L2 Transactions Avg', 'DRAM Transactions Avg']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Network Name</th>\n",
       "      <th>Pass</th>\n",
       "      <th>L2 AI</th>\n",
       "      <th>L1 AI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ResNet50-2</td>\n",
       "      <td>backward</td>\n",
       "      <td>43.267561</td>\n",
       "      <td>23.545340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ResNet50-2</td>\n",
       "      <td>forward</td>\n",
       "      <td>56.834593</td>\n",
       "      <td>29.121282</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Network Name      Pass      L2 AI      L1 AI\n",
       "0   ResNet50-2  backward  43.267561  23.545340\n",
       "1   ResNet50-2   forward  56.834593  29.121282"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#combineddf = combineddf.reset_index()\n",
    "#seldf = combineddf[ (combineddf[\"Network Name\"]==\"ResNet50-2\") &\\\n",
    "#           (combineddf[\"Input Shape\"]==\"112x112x64\") &\\\n",
    "#           (combineddf[\"Precision\"]==\"FP32\")]\n",
    "#seldf\n",
    "#combineddf[[\"FP32 L2 AI\", \"FP32 L1 AI\"]]\n",
    "combineddf[['Network Name', 'Pass', \"L2 AI\", \"L1 AI\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiledf.to_csv(os.path.join(outputdir,\"full_profile.csv\"))\n",
    "combineddf.to_csv(os.path.join(outputdir,\"combined_profile.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
